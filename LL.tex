\documentclass[english]{lipics-stripped}
% \usepackage[utf8]{inputenc}
\usepackage{mathpartir}
% \usepackage{amsmath}
% \usepackage{amsthm}
% \usepackage{amssymb}
\usepackage{bussproofs}
\usepackage{ cmll }
\EnableBpAbbreviations

\title{Linear Logic for Programmers}
\author{Jean-Philippe Bernardy}
\affil{Chalmers University of Technology and University of Gothenburg\\
  \texttt{bernardy@chalmers.se}}
 \authorrunning{J-P. Bernardy}%optional

\Copyright[nc-sa]%choose "nd" or "nc-nd"
          {Jean-Philippe Bernardy}

\input{unicodedefs.tex}

\newenvironment{bloc}{\begin{array}[t]{@{}l@{}}}{\end{array}}
\newcommand{\braces}[1]{\left\{ {#1} \right\} }

\newcommand{\p}[1]{{#1}^{⊥}}
\newcommand{\Let}{\mathsf{let}~}
\newcommand{\In}{~\mathsf{in}~}
\newcommand{\Fst}{\mathsf{fst} }
\newcommand{\Snd}{\mathsf{snd} }
\newcommand{\Inl}{\mathsf{inl}~}
\newcommand{\Inr}{\mathsf{inr}~}
\newcommand{\Case}{\mathsf{case}~}
\newcommand{\Of}{\mathsf{~of}~}
\newcommand{\Connect}[2]{\mathsf{connect}~#1~\mathsf{to}~\braces{#2}}
\newcommand{\ConnectS}[5]{\Connect{#1}{#2 \In #3; #4 \In #5}}
\newcommand{\ConnectB}[5]{\Connect{#1}{
    \begin{array}{l@{\In}l}
      #2 & #3 \\ #4 & #5     
    \end{array}
}}
\newcommand{\newchan}[1]{\mathsf{new}_{#1}}
\newcommand{\chan}[3]{#2 \stackrel{#1}{↔} #3}
\newcommand\layout[1]{[#1]}
\begin{document}

\maketitle

\def\pat{,}
\def\loll{\multimap}
\def\pa{\ensuremath{\parr}}

TODO: make the environment of types explicit. $Θ$

\section{Core LL}

\subsection{Types}
neutral in parens
\[
\begin{array}{ccc}
\text{conjunction} &   \text{disjuction} & \\
 ⊗ ~ (1) &  \pa ~ (⊥) & \text{multiplicative}  \\
 \& ~ (⊤) &  ⊕ ~ (0) & \text{additive}
\end{array}
\]

\begin{tabular}{cc}
{$A ⊗ B$} & $A$ and $B$ in parallel\\
{$A \pa B$}& $A$ when $\p B$ is given, or vice versa. $A ⊸ B ≜ \p A \pa B$. \\
{$A ⊕ B$}& Either $A$ or $B$ (the context choses which)\\
{$A ~\&~ B$}& Either $A$ or $B$ (the program choses which)\\
\end{tabular}

\subsection{An ISWIM syntax for linear-logic sequents}

We have a judgement $Γ ⊢ t$; with only hypotheses and no conclusion. Remarks:
\begin{itemize}
\item In fact, it is as if there were a single $⊥$ conclusion: $Γ ⊢ t
  : ⊥$.  Essentially the programs are written in CPS.  Because the
  return type is always the same, writing it is redundant, so we omit
  it.
\item This is inverted compared to the usual presentation of LL, which
  has only conclusions.
\item As usual in LL, we have only elimination rules; because
  introduction rules are recovered using {\sc Ax} and {\sc Cut}.
\item In sum, when we have an set of hypothesis, if the program is
  ``fed'' inputs for all of them but one, the last one will ``spit
  out'' a result. (In fact, where and how data is read/written cannot
  be predicted from the shallow structure of the sequent, one must to
  a deep analysis of the types.)
\end{itemize}


\begin{mathpar}
\inferrule[Ax]{ }{ x : \p A, y : A ⊢ x ↔ y}
\and
\inferrule[Cut]{Γ, x:\p A ⊢ a \\ y:A, Δ ⊢ b }{Γ,Δ ⊢ \ConnectS {\newchan A} x a y b}
\\
\inferrule[⊗]{Γ, x : A, y : B, Δ ⊢ a}{Γ, z : A ⊗ B, Δ ⊢ \Let ⟨x,y⟩=z \In a}
\and 
\inferrule[\pa]{Γ, x:A ⊢ a\\ y:B, Δ ⊢ b}{ Γ, z:A\pa B, Δ ⊢ \ConnectS z x a y b}
\\
\begin{array}{c}
\inferrule[\&-l]{Γ,x:A ⊢ a} { Γ,z:A~\&~B ⊢ \Let x = \Fst z \In a}\\
\\ 
\inferrule[\&-r]{Γ,y:B ⊢ b} { Γ,z:A~\&~B ⊢ \Let y = \Snd z \In b}\\
\end{array}
\and
\inferrule[⊕]{Γ,x:A ⊢ a \\ Γ,y:B ⊢ b} { Γ,z:A⊕B ⊢ \Case z \Of \{ \Inl x ↦ a ; \Inr y ↦ b  \} }
\\
\inferrule[1]{Γ ⊢ a}{Γ, x:1 ⊢ \Let ⋄ = x \In a} 
\and
\inferrule[⊥]{ }{x:⊥ ⊢ x} 
\\
\text{no rule for ⊤}
\and
\inferrule[0]{ }{Γ,x:0 ⊢ \mathsf{dump~}Γ\mathsf{~into~} x} 
\\
  \inferrule[∃]{Θ,α;Γ,y:A ⊢ b}{Θ;Γ,z:∃α.A ⊢ \Let ⟨α,y⟩ = z \In b }
\and
  \inferrule[∀]{Γ,x:A[B/α] ⊢ b \\ B\text{~valid} }{Γ,z:∀α.A ⊢ \Let x = z∙B \In b }
\\
  \inferrule[?]{!Γ,x:A ⊢ a}{!Γ,x:?A ⊢ \mathsf{offer~}x \In a }
\and
  \inferrule[!]{Γ,x:A ⊢ a}{Γ,x:!A ⊢ \mathsf{demand~}x \In a }
\\
  \inferrule[Weaken]{Γ ⊢ a}{Γ,x:!A ⊢ \mathsf{ignore~}x \In a }
\and
  \inferrule[Contract]{Γ,x:!A,y:!A ⊢ a}{Γ,x:!A ⊢ \Let y = \mathsf{alias~}x \In a }
\end{mathpar}

Explanation of the rules:
\begin{itemize}
\item {\sc Ax} plugs the  $x$ to $y$ (and vice-versa).

  Remark: we do not know from the rule in isolation the ``direction of
  travel'' of information.  Indeed, negation is involutive; so we can
  just reverse the rule by substituting $\p A$ for $A$. 

  However, if $A$ is a monomorphic base type, we can interpret the \emph{instance}
  of the rule to be communication in a specific direction.


\item {\sc Cut}: creates a new communication channel of type $A$;
  naming the ends $x$ and $y$. Programs ``talking'' on either end
  execute in parallel.

  Note that the communication channel is ``one-shot''; but the type of
  the channel may be a list/stream/what have you. There may even be
  back and forth communication if the type involes eg. a linear arrows.

  (iirc, Wadler 2012 makes the opposite choice).

\item {\sc $⊗$}: Essentially no-op. Just gives names to more hypothesis.
\item {\sc \pa}: executes two processes in parallel. Note that the
  only with possible communication is via $z$; the parts $Γ$ and $Δ$
  can be seen as separate memories in the rhs. The situation is
  similar for {\sc Cut}.


\item {\sc ⊕}: does case analysis
\item {\sc \&}: choses a side
\item Because there is no elim rule for ⊤, 0 can never be constructed.
\end{itemize}
TODO: exponentials.

\subsection{Example}
Let us prove/program $A ⊗ B ⊸ B ⊗ A$. Putting everything as
hypotheses, we must find some $p$ with
%
\[x : A ⊗ B, y : \p {(B ⊗ A)} ⊢ p\]
%
Expanding the definition of negation:

\begin{align*}
  x : A ⊗ B, y : \p B \pa \p A ⊢ p\\
  p & = \Let ⟨v:A,w:B⟩ = x \In  \\
    & \quad \ConnectB y {t:\p B} {t ↔ w} {u : \p A} {u ↔ v}
\end{align*}

\subsection{Reduction rules (Incomplete)}

\begin{mathpar}
  \ConnectB {\newchan {A ⊗ B}} x {\ConnectS x v a w b} y {\Let ⟨t,u⟩=y \In c} \\ ~⟶~  \ConnectB {\newchan A} v {a} {t} {\ConnectB {\newchan B} w b u c }
\end{mathpar}


\begin{align*}
\ConnectB {\newchan A} x {x ↔ z} y t & ~⟶~ t[z/x] \\ 
\ConnectB {\newchan {A⊕B}} x {\Let z = \Fst x \In a} y {\Case y \Of \{ \Inl t ↦ b ; \Inr u ↦ c  \}} & ~⟶~ \ConnectB {\newchan A} z a t b \\
\ConnectB {\newchan {}} {x:∀α.A} {\Let t = x ∙ B \In a} {y:∃α.\p A} {\Let ⟨α,u⟩ = y \In b }  & ~⟶~ \ConnectB {\newchan {}} {t:A[B/α]} {a} {u:\p{A[B/α]}} {b} 
\end{align*}

\begin{mathpar}
\ConnectB{!A} x {\mathsf{offer~}x \In a} y {\mathsf{demand~}y \In b} ~⟶~  \ConnectB{A} x {a} y {b}
\end{mathpar}

\begin{mathpar}
\ConnectB{!A} x {\mathsf{ignore~}x \In a} y {\mathsf{offer~}y \In b} ~⟶~  a
\end{mathpar}

\subsection{Abstract machine}

Problems of the reduction rules:
\begin{itemize}
\item they are synchronous (eg. Top/Bottom are eliminated \emph{at the same time})
\item they force arbitrary sequentialisation. (eg. Par/Tensor is asymetric)
\end{itemize}

The idea of the AM is to delay cut-elimination in order to get a more
efficient execution (as in eg. Krivine's abstract machine). (One might
say that the AM realises ``cut-preservation''.) Concurrent semantics
naturally arise.

The AM reduces/executes a number of closures concurrently. (Each
closure can be thought of as a process.)  A closure is a sequent
together with an environment. An environment has for each variable
$x:A$ in the context a pointer to a memory area of layout $\layout A$.
(Each variable can be thought of as a channel.)  Note
that we will execute closed programs only, so there is no ``open''
environment: each variable is connected.

The translation of each type to a memory layout is: ($·$ indicates sequence)
\begin{align*}
  \layout{A⊗B} = \layout{A \pa B}  &= \layout A · \layout B\\
  \layout{A ⊕ B} = \layout{A \& B} &= \text{1 bit of info + 1 bit indicating that the data is ready} · (\layout A \mid \layout B)\\
  \layout{α} = \layout{\p{α}} &= ρ[α] \\
  \layout{!\p A} = \layout{?A} &= \text{pointer to a closure (with $A$ as last variable) + ready flag + reference count; aka. a thunk} \\
  \layout{∀α.A} = \layout{∃α.A} &= \text{cell} + \layout{A} \\
  \layout{T} &= \epsilon & T ∈ \braces{⊤,⊥,0,1}
\end{align*}
Note that $\layout A = \layout{\p A}$, but the data is used differently, see below.


Operational behaviour of the rules:
\begin{itemize}
\item 0: crash
\item 1: continue
\item ⊥: terminate (delete the closure)
\item ⊕: wait for the data to be ready; then chose a branch according
  to the tag. Free the pointer and the tag.  Free the non-used part of the disjunction.
\item \&-L: Allocate $\layout A$ and initialise it. Write the tag and the pointer. Continue.
\item $x:(A ⊗ B)$: add an entry in the context for $y:B$, at location
  $x+\layout A$ (No communication occurs!)
\item $A \pa B$: split the environment and spawn a new closure. (No communication either)
\item $∀$. Write the representation of the concrete type $B$ (found in the code) to the 1st cell.
\item $∃$. Split the variables as in $⊗$.
\item Cut: similar to $\pa$ but connects the two closures directly together.
\item Ax: Copy the data between the closures. For type variables, wait for the type to be ready, use
  the type representation from the environment.
\item ?: place a pointer to the closure $a$ in the zone pointed by
  $x:?A$, mark as ready; terminate.
\item !: wait for ready. Allocate and initialise memory of $\layout A$, spawn a
  closure from the zone pointed by $x:!A$, link it with $x$ and
  continue. Decrement reference count.
\item Contract: copy the pointer to the thunk, increment reference
  count.  Note this is easy in the AM compared to the cut-elim.
\item Weaken: discard the pointer, decrement reference count.
\end{itemize}

Don't forget about recursively decrementing counts upon deallocation.

TODO:
 How to represent the heap?


\section{Cut and update the world}
Can linear types change the world?

Assume a type $W$ containing the state of the world. Two sequents can
be composed by Cut:

\AXC {$W,\p W, \p X ⊢ $}
\AXC {$W,\p W, \p Y⊢ $ }
\LL{\sc Cut $W$}\BIC{$W,\p W, \p X, \p Y⊢ $}
\UIC{$W,\p W, {(\p X ⊗ \p Y)}⊢ $}
\UIC{$W,\p W, \p {(X \pa Y)}⊢ $}
\DisplayProof

Maybe if $W$ is abstract enough it's possible to update it in place.

\section{Functional Syntax}
(fragments; see DILL for the rest)
\begin{mathpar}
\inferrule{Γ, x:\p A ⊢ a}{Γ ⊢ \mathsf{return} ~x:\p A~ \mathsf{from} ~a : A}
\and \inferrule{Γ ⊢ a : A \\ Δ ⊢ b}{Γ,Δ,x:\p A ⊢ \Let x = a \In b}
\\
\and \inferrule{Γ ⊢ a : A \\ Δ ⊢ b : B}{Γ,Δ ⊢ ⟨a,b⟩ : A⊗B}
\\
% ??? \and \inferrule{Γ ⊢ f : A ⊸ B \\ Δ ⊢ a : B}{Γ ⊢ f a : B}
\and \inferrule{Γ,x:A ⊢ b:B}{Γ ⊢ λx:A.b : A ⊸ B}
\\
\and \inferrule{Γ ⊢ a : A}{Γ ⊢ \Inl a : A ⊕ B}
 
\end{mathpar}


\begin{mathpar}
\end{mathpar}



\end{document}


